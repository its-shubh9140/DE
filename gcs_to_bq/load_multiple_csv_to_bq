import os
import json

from google.cloud import bigquery, client
import datetime

from google.cloud.storage import blob
from myfolder.list_objects_with_given_prifix import list_blobs_with_prefix


from myfolder.my_data import data, mail_addr, table
from myfolder.sending_mail import send_email


def csv_loader():
    client = bigquery.Client.from_service_account_json("C:\\Users\\prateek\\Downloads\\de-training-project-3fb8c9f7d834.json")

# TODO(developer): Set table_id to the ID of the table to create.
# table_id = "your-project.your_dataset.your_table_name"

    job_config = bigquery.LoadJobConfig(
    schema=[
        #bigquery.SchemaField("serial_no", "INTEGER"),
        bigquery.SchemaField("roles", "STRING"),
        bigquery.SchemaField("companies", "STRING"),
        bigquery.SchemaField("locations", "STRING"),
        bigquery.SchemaField("experience", "STRING"),
        bigquery.SchemaField("skills", "STRING"),
        bigquery.SchemaField("job_posted_date", "DATE"),
        bigquery.SchemaField("scraper_run_date_time", "DATETIME"),
        bigquery.SchemaField("url", "STRING"),
    ],
    skip_leading_rows=1,
    # The source format defaults to CSV, so the line below is optional.
    source_format=bigquery.SourceFormat.CSV,
)

    csv_files=list_blobs_with_prefix("training-demo-project", prefix='csv_files_with_date_time', delimiter='none')
    print(csv_files)

    for path in csv_files:
        uri = "gs://training-demo-project/"+path
        print(uri)


# static load it from later
        try:
        #table_id="de-training-project.jobs_info_naukri.jobs"
            table_id=table


            load_job = client.load_table_from_uri(uri, table_id, job_config=job_config)  # Make an API request.


#mport dat time and str(datetime.now())

            load_job.result()  # Waits for the job to complete.
            destination_table = client.get_table(table_id)  # Make an API request.
            print("Loaded {} rows.".format(destination_table.num_rows))
            x=datetime.datetime.now().replace(microsecond=0)
           #print(x+"Ptr")
            sub = ' file ' + str(uri) + ' loaded successfully ' + ' into bigquery at ' + str(x)
            send_email(mail_addr,sub)
        except Exception as e:
            print(e)
    #send_email(["sarojprateekkumar@gmail.com","megha.vishwase@mediaagility.com ","mayuresh.bharmoria@mediaagility.com"],'')
            x=datetime.datetime.now().replace(microsecond=0)
            sub=' File ' +str(uri) +' is not loaded into bigquery at '+ str(x) + '. error found : '+ str(e)
            send_email(mail_addr, sub)
            print('Error Occured while loading data')

csv_loader()









